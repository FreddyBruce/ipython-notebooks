{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Bike Sharing Trends\n",
    "\n",
    "## Problem Statement\n",
    "With environmental issues and health becoming trending topics, usage of bicycles as a mode of transportation has gained traction in recent years. To encourage bike usage, cities across the world have successfully rolled out bike sharing programs. Under such schemes, riders can rent bicycles using manual/ automated kiosks spread across the city for defined periods. In most cases, riders can pick up bikes from one location and return them to any other designated place.\n",
    "\n",
    "The bike sharing platforms from across the world are hotspots of all sorts of data, ranging from travel time, start and end location, demographics of riders, and so on. This data along with alternate sources\n",
    "of information such as weather, traffic, terrain, and so on makes it an attractive proposition for different research areas.\n",
    "\n",
    "The Capital Bike Sharing dataset contains information related to one such bike sharing program underway in Washington DC. Given this augmented (bike sharing details along with weather information) dataset, can we forecast bike rental demand for this program?\n",
    "\n",
    "## Exploratory Analysis\n",
    "Now that we have an overview of the business case and a formal problem statement, the very next stage is to explore and understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour = pd.read_csv('data/hour.csv')\n",
    "print(\"Shape of dataset::{}\".format(df_hour.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the documentation for the dataset, there are bike sharing as well as weather attributes available. The attribute dteday would require type conversion from object (or string type) to timestamp. Attributes like season, holiday, weekday, and so on are inferred as integers by pandas, and they would require conversion to categoricals for proper understanding.\n",
    "\n",
    "Before jumping into type casting attributes, the following snippet cleans up the attribute names to make them more understandable and pythonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.rename(columns={'instant':'rec_id',\n",
    "                        'dteday':'datetime',\n",
    "                        'holiday':'is_holiday',\n",
    "                        'workingday':'is_workingday',\n",
    "                        'weathersit':'weather_condition',\n",
    "                        'hum':'humidity',\n",
    "                        'mnth':'month',\n",
    "                        'cnt':'total_count',\n",
    "                        'hr':'hour','yr':'year'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have attribute names cleaned up, we perform type-casting of attributes. The following snippet gets the attributes into the proper data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date time conversion\n",
    "df_hour['datetime'] = pd.to_datetime(df_hour.datetime)\n",
    "\n",
    "# categorical variables\n",
    "df_hour['season'] = df_hour.season.astype('category')\n",
    "df_hour['is_holiday'] = df_hour.is_holiday.astype('category')\n",
    "df_hour['weekday'] = df_hour.weekday.astype('category')\n",
    "df_hour['weather_condition'] = df_hour.weather_condition.astype('category')\n",
    "df_hour['is_workingday'] = df_hour.is_workingday.astype('category')\n",
    "df_hour['month'] = df_hour.month.astype('category')\n",
    "df_hour['year'] = df_hour.year.astype('category')\n",
    "df_hour['hour'] = df_hour.hour.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution and Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sn.pointplot(data=df_hour[['hour',\n",
    "                           'total_count',\n",
    "                           'season']],\n",
    "             x='hour', y='total_count',\n",
    "             hue='season', ax=ax)\n",
    "ax.set(title=\"Season wise hourly distribution of counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows similar trends for all seasons with counts peaking in the morning between 7-9 am and in the evening between 4-6 pm, possibly due to high movement during start and end of office hours. The counts are lowest for the spring season, while fall sees highest riders across all 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.pointplot(data=df_hour[['hour',\n",
    "                           'total_count',\n",
    "                           'weekday']],\n",
    "             x='hour', y='total_count',\n",
    "             hue='weekday', ax=ax)\n",
    "ax.set(title=\"Weekday wise hourly distribution of counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, distribution of ridership across days of the week also presents interesting trends of higher usage during afternoon hours over weekends, while weekdays see higher usage during mornings and evenings.\n",
    "\n",
    "Having observed hourly distribution of data across different categoricals, letâ€™s see if there are any aggregated trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.barplot(data=df_hour[['month',\n",
    "                         'total_count']],\n",
    "           x=\"month\",y=\"total_count\")\n",
    "ax.set(title=\"Monthly distribution of counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.violinplot(data=hour_df[['year',\n",
    "                            'total_count']],\n",
    "              x=\"year\",y=\"total_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet plots yearly distribution on violin plots. The figure above clearly helps us understand the multimodal distribution in both 2011 and 2012 ridership counts with 2011 having peaks at lower values as compared to 2012. The spread of counts is also much more for 2012, although the max density for both the years is between 100-200 rides.\n",
    "\n",
    "### Outliers\n",
    "While exploring and learning about any dataset, it is imperative that we check for extreme and unlikely values. Though we handle missing and incorrect information while preprocessing the dataset, outliers are usually caught during EDA. Outliers can severely and adversely impact the downstream steps like modeling and the results.\n",
    "We usually utilize boxplots to check for outliers in the data. In the following snippet, we analyze outliers for numeric attributes like total_count, temperature, and wind_speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)= plt.subplots(ncols=2)\n",
    "sns.boxplot(data=df_hour[['total_count','casual','registered']],ax=ax1)\n",
    "sns.boxplot(data=df_hour[['temp','windspeed']],ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily mark out that for the three count related attributes, all of them seem to have a sizable number of outlier values. The casual rider distribution has overall lower numbers though. For weather attributes of temperature and wind speed, we find outliers only in the case of wind speed.\n",
    "\n",
    "We can similarly try to check outliers at different granularity levels like hourly, monthly, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots()\n",
    "sns.boxplot(data=df_hour[['hour','total_count']],ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = df_hour[['temp','atemp',\n",
    "                   'humidity','windspeed',\n",
    "                   'casual', 'registered',\n",
    "                   'total_count']].corr()\n",
    "mask = np.array(corrMatt)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "sn.heatmap(corrMatt, mask=mask,\n",
    "           vmax=.8, square=True,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two count variables, registered and casual, show obvious strong correlation to total_count. Similarly, temp and atemp show high correlation. wind_speed and humidity have slight negative correlation. Overall, none of the attributes show high correlational statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "Regression analysis is a statistical modeling technique. It is the process of investigating relationships between dependent and independent variables. Regression itself includes a variety of techniques for modeling and analyzing relationships between variables. It is widely used for predictive analysis, forecasting, and time series analysis.\n",
    "The dependent or target variable is estimated as a function of independent or predictor variables. The estimation function is called the regression function.\n",
    "\n",
    "The height-weight relationship is a classic example to get started with regression analysis. The example states that weight of a person is dependent on his/her height. Thus, we can formulate a regression function to estimate the weight (dependent variable) given height (independent variable) of a person, provided we have enough training examples. We discuss more on this in the coming section.\n",
    "\n",
    "Regression analysis models the relationship between dependent and independent variables. It should be kept in mind that correlation between dependent and independent variables does not imply causation!\n",
    "\n",
    "### Assumptions\n",
    "Assumptions\n",
    "Regression analysis has a few general assumptions while specific analysis techniques have added (or reduced) assumptions as well. The following are important general assumptions for regression analysis:\n",
    "* The training dataset needs to be representative of the population being modeled.\n",
    "* The independent variables are linearly independent, i.e., one independent variable cannot be explained as a linear combination of others. In other words, there should be no multicollinearity.\n",
    "* Homoscedasticity of error, i.e. the variance of error, is consistent across the sample.\n",
    "\n",
    "### Evaluation Criteria\n",
    "Evaluation of model performance is an important aspect of modelling. We should be able to not just understand the outcomes but also evaluate how models compare to each other or whether the performance is acceptable or not.\n",
    "In general, evaluation metrics and performance guidelines are pretty use case and domain specific, regression analysis often uses a few standard metrics.\n",
    "\n",
    "#### Residual Analysis\n",
    "#### Normality Test (Q-Q Plot)\n",
    "#### R-Squared: Goodness of Fit\n",
    "#### Cross Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
